{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./new_data/train_accident_normalized_text.csv')\n",
    "df_test = pd.read_csv('./new_data/test_accident_normalized_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_LSTM_Base(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        samples, targets = batch\n",
    "        outputs = self(samples.double())\n",
    "        loss = nn.functional.mse_loss(outputs, targets)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaRNN(RNN_LSTM_Base):\n",
    "    def __init__(self, in_size, hid_size_rnn, hid_size_lin, out_size, n_layers=1):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "# Define dimensions for the layers\n",
    "        self.input_size = in_size\n",
    "        self.hidden_size_rnn = hid_size_rnn\n",
    "        self.hidden_size_lin = hid_size_lin\n",
    "        self.output_size = out_size\n",
    "        self.n_layers = n_layers\n",
    "# Defining the RNN layer\n",
    "        self.rnn = nn.RNN(in_size, hid_size_rnn, n_layers, batch_first=True)\n",
    "# Defining the linear layer\n",
    "        self.linear = nn.Linear(hid_size_lin, out_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "# x must be of shape (batch_size, seq_len, input_size)\n",
    "    xb = x.view(x.size(0), x.size(1), self.input_size).double()\n",
    "# Initialize the hidden layer's array of shape (n_layers*n_dirs, batch_size, hidden_size_rnn)\n",
    "    h0 = torch.zeros(self.n_layers, x.size(0), self.hidden_size_rnn, requires_grad=True).double()\n",
    "# out is of shape (batch_size, seq_len, num_dirs*hidden_size_rnn)\n",
    "    out, hn = self.rnn(xb, h0)\n",
    "# out needs to be reshaped into dimensions (batch_size, hidden_size_lin)\n",
    "    out = out.reshape(x.size(0), self.hidden_size_lin)\n",
    "    out = nn.functional.relu(out)\n",
    "# Finally we get out in the shape (batch_size, output_size)\n",
    "    out = self.linear(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, lr, model, train_loader, test_loader, opt_func=torch.optim.SGD):\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "# Training phase\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "# Calculate gradients from chain rule\n",
    "            loss.backward()\n",
    "# Apply gradient descent step\n",
    "            optimizer.step()\n",
    "# Remove gradients for next iteration\n",
    "            optimizer.zero_grad()\n",
    "    return 'Trained for {} epochs'.format(epochs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
